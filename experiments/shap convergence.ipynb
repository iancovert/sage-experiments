{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "import shap_sampling\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = sage.datasets.bank()\n",
    "\n",
    "# Feature names and categorical columns (for CatBoost model)\n",
    "feature_names = df.columns.tolist()[:-1]\n",
    "categorical_cols = ['Job', 'Marital', 'Education', 'Default', 'Housing',\n",
    "                    'Loan', 'Contact', 'Month', 'Prev Outcome']\n",
    "categorical_inds = [feature_names.index(col) for col in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, test = train_test_split(\n",
    "    df.values, test_size=int(0.1 * len(df.values)), random_state=123)\n",
    "train, val = train_test_split(\n",
    "    train, test_size=int(0.1 * len(df.values)), random_state=123)\n",
    "Y_train = train[:, -1].copy().astype(int)\n",
    "Y_val = val[:, -1].copy().astype(int)\n",
    "Y_test = test[:, -1].copy().astype(int)\n",
    "train = train[:, :-1].copy()\n",
    "val = val[:, :-1].copy()\n",
    "test = test[:, :-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_models/bank model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_final = sage.load('results/bank_sage.pkl')\n",
    "final_values = sage_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and calculate\n",
    "imputer = sage.MarginalImputer(model, test[:512])\n",
    "estimator = shap_sampling.SHAPEstimator(imputer, 'cross entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "permutations_list = []\n",
    "for i in range(16):\n",
    "    x = test[i:i+1]\n",
    "    y = Y_test[i:i+1]\n",
    "    shap_values = estimator(x, y, batch_size=16, thresh=0.01, verbose=False, bar=True)\n",
    "    permutations_list.append(shap_values.n_permutations)\n",
    "    print('Done with {} ({} permutations)'.format(i, permutations_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_permutations = np.mean(permutations_list)\n",
    "median_permutations = np.median(permutations_list)\n",
    "num_permutations = (mean_permutations // 32) * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values_list = []\n",
    "for i in range(512):\n",
    "    x = test[i:i+1]\n",
    "    y = Y_test[i:i+1]\n",
    "    shap_values = estimator(x, y, batch_size=32, n_permutations=num_permutations,\n",
    "                          detect_convergence=False, verbose=False, bar=False)\n",
    "    values_list.append(shap_values.values)\n",
    "    corr = np.corrcoef(np.array(values_list).mean(axis=0), final_values)[0, 1]\n",
    "    print(i, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'values': np.array(values_list),\n",
    "    'evals': median_permutations * len(feature_names),\n",
    "    'inner_samples': 512\n",
    "}\n",
    "with open('results/bank shap convergence.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "import shap_sampling\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = sage.datasets.bike()\n",
    "feature_names = df.columns.tolist()[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data, with total count serving as regression target\n",
    "train, test = train_test_split(\n",
    "    df.values, test_size=int(0.1 * len(df.values)), random_state=123)\n",
    "train, val = train_test_split(\n",
    "    train, test_size=int(0.1 * len(df.values)), random_state=123)\n",
    "Y_train = train[:, -1].copy()\n",
    "Y_val = val[:, -1].copy()\n",
    "Y_test = test[:, -1].copy()\n",
    "train = train[:, :-3].copy()\n",
    "val = val[:, :-3].copy()\n",
    "test = test[:, :-3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_models/bike model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_final = sage.load('results/bike_sage.pkl')\n",
    "final_values = sage_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and calculate\n",
    "imputer = sage.MarginalImputer(model, test[:512])\n",
    "estimator = shap_sampling.SHAPEstimator(imputer, 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations_list = []\n",
    "for i in range(16):\n",
    "    x = test[i:i+1]\n",
    "    y = Y_test[i:i+1]\n",
    "    shap_values = estimator(x, y, batch_size=128, thresh=0.01, verbose=False, bar=True)\n",
    "    permutations_list.append(shap_values.n_permutations)\n",
    "    print('Done with {} ({} permutations)'.format(i, permutations_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_permutations = np.mean(permutations_list)\n",
    "median_permutations = np.median(permutations_list)\n",
    "num_permutations = (mean_permutations // 32) * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_list = []\n",
    "for i in range(512):\n",
    "    x = test[i:i+1]\n",
    "    y = Y_test[i:i+1]\n",
    "    shap_values = estimator(x, y, batch_size=32, n_permutations=num_permutations,\n",
    "                          detect_convergence=False, verbose=False, bar=False)\n",
    "    values_list.append(shap_values.values)\n",
    "    corr = np.corrcoef(np.array(values_list).mean(axis=0), final_values)[0, 1]\n",
    "    print(i, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'values': np.array(values_list),\n",
    "    'evals': median_permutations * len(feature_names),\n",
    "    'inner_samples': 512\n",
    "}\n",
    "with open('results/bike shap convergence.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "import pickle\n",
    "import shap_sampling\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = sage.datasets.credit()\n",
    "\n",
    "# Feature names and categorical columns (for CatBoost model)\n",
    "feature_names = df.columns.tolist()[:-1]\n",
    "categorical_columns = [\n",
    "    'Checking Status', 'Credit History', 'Purpose', 'Credit Amount',\n",
    "    'Savings Account/Bonds', 'Employment Since', 'Personal Status',\n",
    "    'Debtors/Guarantors', 'Property Type', 'Other Installment Plans',\n",
    "    'Housing Ownership', 'Job', 'Telephone', 'Foreign Worker'\n",
    "]\n",
    "categorical_inds = [feature_names.index(col) for col in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, test = train_test_split(\n",
    "    df.values, test_size=int(0.1 * len(df.values)), random_state=0)\n",
    "train, val = train_test_split(\n",
    "    train, test_size=int(0.1 * len(df.values)), random_state=0)\n",
    "Y_train = train[:, -1].copy().astype(int)\n",
    "Y_val = val[:, -1].copy().astype(int)\n",
    "Y_test = test[:, -1].copy().astype(int)\n",
    "train = train[:, :-1].copy()\n",
    "val = val[:, :-1].copy()\n",
    "test = test[:, :-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_models/credit model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_final = sage.load('results/credit_sage.pkl')\n",
    "final_values = sage_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and calculate\n",
    "imputer = sage.MarginalImputer(model, train[:512])\n",
    "estimator = shap_sampling.SHAPEstimator(imputer, 'cross entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "permutations_list = []\n",
    "for i in range(16):\n",
    "    x = test[i:i+1]\n",
    "    y = Y_test[i:i+1]\n",
    "    shap_values = estimator(x, y, batch_size=16, thresh=0.01, verbose=False, bar=True)\n",
    "    permutations_list.append(shap_values.n_permutations)\n",
    "    print('Done with {} ({} permutations)'.format(i, permutations_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_permutations = np.mean(permutations_list)\n",
    "median_permutations = np.median(permutations_list)\n",
    "num_permutations = (mean_permutations // 32) * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values_list = []\n",
    "for i in range(100):\n",
    "    x = test[i:i+1]\n",
    "    y = Y_test[i:i+1]\n",
    "    shap_values = estimator(x, y, batch_size=32, n_permutations=num_permutations,\n",
    "                          detect_convergence=False, verbose=False, bar=False)\n",
    "    values_list.append(shap_values.values)\n",
    "    corr = np.corrcoef(np.array(values_list).mean(axis=0), final_values)[0, 1]\n",
    "    print(i, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'values': np.array(values_list),\n",
    "    'evals': num_permutations * len(feature_names),\n",
    "    'inner_samples': 512\n",
    "}\n",
    "with open('results/credit shap convergence.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
