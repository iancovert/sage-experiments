{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train set\n",
    "train = dsets.MNIST('../data', train=True, download=True)\n",
    "imgs = train.data.reshape(-1, 784) / 255.0\n",
    "labels = train.targets\n",
    "\n",
    "# Shuffle and split into train and val\n",
    "inds = torch.randperm(len(train))\n",
    "imgs = imgs[inds]\n",
    "labels = labels[inds]\n",
    "val, Y_val = imgs[:6000], labels[:6000]\n",
    "train, Y_train = imgs[6000:], labels[6000:]\n",
    "\n",
    "# Load test set\n",
    "test = dsets.MNIST('../data', train=False, download=True)\n",
    "test, Y_test = test.data.reshape(-1, 784) / 255.0, test.targets\n",
    "\n",
    "# Move test data to numpy\n",
    "test_np = test.cpu().data.numpy()\n",
    "Y_test_np = Y_test.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train, Y_train, val, Y_val):\n",
    "    # Create model\n",
    "    device = torch.device('cuda', 1)\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(train.shape[1], 256),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(256, 10)).to(device)\n",
    "\n",
    "    # Training parameters\n",
    "    lr = 1e-3\n",
    "    mbsize = 64\n",
    "    max_nepochs = 250\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    lookback = 5\n",
    "    verbose = False\n",
    "\n",
    "    # Move to GPU\n",
    "    train = train.to(device)\n",
    "    val = val.to(device)\n",
    "    # test = test.to(device)\n",
    "    Y_train = Y_train.to(device)\n",
    "    Y_val = Y_val.to(device)\n",
    "    # Y_test = Y_test.to(device)\n",
    "\n",
    "    # Data loader\n",
    "    train_set = TensorDataset(train, Y_train)\n",
    "    train_loader = DataLoader(train_set, batch_size=mbsize, shuffle=True)\n",
    "\n",
    "    # Setup\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    min_criterion = np.inf\n",
    "    min_epoch = 0\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(max_nepochs):\n",
    "        for x, y in train_loader:\n",
    "            # Move to device.\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Take gradient step.\n",
    "            loss = loss_fn(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        # Check progress.\n",
    "        with torch.no_grad():\n",
    "            # Calculate validation loss.\n",
    "            val_loss = loss_fn(model(val), Y_val).item()\n",
    "            if verbose:\n",
    "                print('{}Epoch = {}{}'.format('-' * 10, epoch + 1, '-' * 10))\n",
    "                print('Val loss = {:.4f}'.format(val_loss))\n",
    "\n",
    "            # Check convergence criterion.\n",
    "            if val_loss < min_criterion:\n",
    "                min_criterion = val_loss\n",
    "                min_epoch = epoch\n",
    "                best_model = deepcopy(model)\n",
    "            elif (epoch - min_epoch) == lookback:\n",
    "                if verbose:\n",
    "                    print('Stopping early')\n",
    "                break\n",
    "\n",
    "    # Keep best model\n",
    "    model = best_model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_values = sage.load('results/mnist_sage_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/mnist mean_importance.pkl', 'rb') as f:\n",
    "    mean_imp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = []\n",
    "for i in range(512):\n",
    "    filename = 'results/mnist permutation_test {}.pkl'.format(i)\n",
    "    with open(filename, 'rb') as f:\n",
    "        permutation.append(pickle.load(f)['scores'])\n",
    "permutation = np.array(permutation).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/mnist feature_ablation.pkl', 'rb') as f:\n",
    "    ablation = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/mnist univariate.pkl', 'rb') as f:\n",
    "    univariate = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = (sage_values.values, permutation, mean_imp, ablation, univariate)\n",
    "names = ('SAGE', 'Permutation Test', 'Mean Importance', 'Feature Ablation', 'Univariate')\n",
    "mnist_results = {name: {'values': imp} for (imp, name) in zip(importance, names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "num_features = list(range(5, 55, 5))\n",
    "\n",
    "for name in mnist_results.keys():\n",
    "    values = mnist_results[name]['values']\n",
    "    order = np.argsort(values)[::-1]\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for num in num_features:\n",
    "        # Subsample data\n",
    "        inds = order[:num]\n",
    "        inds = np.array([i in inds for i in range(784)])\n",
    "        train_small = train[:, inds]\n",
    "        val_small = val[:, inds]\n",
    "        test_small = test[:, inds]\n",
    "        \n",
    "        # Train model\n",
    "        model = train_model(train_small, Y_train, val_small, Y_val)\n",
    "        preds = model(test_small.to(device)).softmax(dim=1).cpu().data.numpy()\n",
    "        loss = log_loss(Y_test_np, preds)\n",
    "        acc = np.mean(np.argmax(preds, axis=1) == Y_test_np)\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        print('Done with {} {} (loss = {:.4f}, acc = {:.4f})'.format(name, num, loss, acc))\n",
    "    \n",
    "    mnist_results[name]['selection'] = loss_list\n",
    "    mnist_results[name]['accuracy'] = acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "num_features = list(range(5, 55, 5))\n",
    "\n",
    "for name in mnist_results.keys():\n",
    "    values = mnist_results[name]['values']\n",
    "    order = np.argsort(values)[::-1]\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for num in num_features:\n",
    "        # Subsample data\n",
    "        inds = order[-num:]\n",
    "        inds = np.array([i in inds for i in range(784)])\n",
    "        train_small = train[:, inds]\n",
    "        val_small = val[:, inds]\n",
    "        test_small = test[:, inds]\n",
    "        \n",
    "        # Train model\n",
    "        model = train_model(train_small, Y_train, val_small, Y_val)\n",
    "        preds = model(test_small.to(device)).softmax(dim=1).cpu().data.numpy()\n",
    "        loss = log_loss(Y_test_np, preds)\n",
    "        acc = np.mean(np.argmax(preds, axis=1) == Y_test_np)\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        print('Done with {} {} (loss = {:.4f}, acc = {:.4f})'.format(name, num, loss, acc))\n",
    "    \n",
    "    mnist_results[name]['inv_selection'] = loss_list\n",
    "    mnist_results[name]['inv_accuracy'] = acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "names = ('Permutation Test', 'Mean Importance', 'Feature Ablation', 'Univariate', 'SAGE')\n",
    "colors = ('tab:blue', 'tab:gray', 'tab:green', 'tab:olive', 'tab:pink')\n",
    "\n",
    "# Selection\n",
    "ax = axarr[0]\n",
    "plt.sca(ax)\n",
    "for name, color in zip(names, colors):\n",
    "    values = mnist_results[name]['accuracy']\n",
    "    plt.plot(num_features, values, color=color, label=name,\n",
    "             marker='o', linestyle='--')\n",
    "plt.ylabel('Accuracy', fontsize=18)\n",
    "plt.xlabel('# Features', fontsize=18)\n",
    "plt.tick_params(labelsize=16)\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "plt.title('MNIST Important Features', fontsize=20)\n",
    "\n",
    "# Inverse selection\n",
    "ax = axarr[1]\n",
    "plt.sca(ax)\n",
    "for name, color in zip(names, colors):\n",
    "    values = mnist_results[name]['inv_accuracy']\n",
    "    plt.plot(num_features, values, color=color, label=name,\n",
    "             marker='o', linestyle='--')\n",
    "plt.xlabel('# Features', fontsize=18)\n",
    "plt.tick_params(labelsize=16)\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "plt.title('MNIST Unimportant Features', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('figures/feature_selection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
